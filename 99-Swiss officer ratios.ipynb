{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 30%; float: right; margin: 10px; margin-right: 5%;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/FHNW_Logo.svg/2560px-FHNW_Logo.svg.png\" width=\"500\" style=\"float: left; filter: invert(50%);\"/>\n",
    "</div>\n",
    "\n",
    "<h1 style=\"text-align: left; margin-top: 10px; float: left; width: 60%;\">\n",
    "    SAN Projekt:<br> Schweizer Offshore Firmen\n",
    "</h1>\n",
    "\n",
    "<p style=\"clear: both; text-align: left;\">\n",
    "    Bearbeitet durch Florin Barbisch, Gabriel Torres Gamez und Tobias Buess im FS 2024.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir führen eine Voranalyse für das Bundesamt für Statistik durch, um die kürzlich aufgetretenen Leaks aus den Offshore Papers zu untersuchen. \n",
    "\n",
    "Diese Analyse zielt darauf ab, Umfang und Natur der Verbindungen in Schweizer Offshore-Strukturen zu ermitteln. Wir verwenden dafür Daten aus der [Offshore Leaks Database](https://offshoreleaks.icij.org/), um mögliche Muster, wichtige Personen aufzudecken, die für die Steuerbehörden oder Regulierungsorgane von Interesse sein könnten. \n",
    "\n",
    "Unsere Arbeit umfasst eine detaillierte Prüfung der betroffenen Entitäten. Dies wird es dem Bundesamt für Statistik ermöglichen, fundierte Entscheidungen zur weiteren Untersuchung und möglichen Massnahmen zu treffen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports und Einstellungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Environment:\n",
      " | Python version: 3.11.5 (tags/v3.11.5:cce6ba9, Aug 24 2023, 14:38:34) [MSC v.1936 64 bit (AMD64)]\n",
      " | Numpy version: 1.26.4\n",
      " | Pandas version: 2.2.2\n",
      " | Matplotlib version: 3.8.4\n",
      " | NetworkX version: 3.3\n",
      " | NetworkX backend: None\n",
      " | CuGraph not installed, for better performance install it like this:\n",
      "\tpip install cugraph-cu12 --extra-index-url=https://pypi.ngc.nvidia.com\n",
      "\n",
      "Ressources:\n",
      " | CPU: 12 cores\n"
     ]
    }
   ],
   "source": [
    "# Python internal modules\n",
    "import os\n",
    "\n",
    "# Project modules\n",
    "import utils\n",
    "\n",
    "# External modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "BACKEND = None  # use default\n",
    "if \"cugraph\" in nx.utils.backends.backends.keys():\n",
    "    import nx_cugraph as nxcg\n",
    "\n",
    "    BACKEND = \"cugraph\"\n",
    "\n",
    "print(\"Python Environment:\")\n",
    "print(f\" | Python version: {os.sys.version}\")\n",
    "print(f\" | Numpy version: {np.__version__}\")\n",
    "print(f\" | Pandas version: {pd.__version__}\")\n",
    "print(f\" | Matplotlib version: {matplotlib.__version__}\")\n",
    "print(f\" | NetworkX version: {nx.__version__}\")\n",
    "print(f\" | NetworkX backend: {BACKEND}\")\n",
    "print(\n",
    "    f\" | CuGraph version: {nxcg.__version__}\"\n",
    "    if BACKEND == \"cugraph\"\n",
    "    else \" | CuGraph not installed, for better performance install it like this:\\n\\tpip install cugraph-cu12 --extra-index-url=https://pypi.ngc.nvidia.com\"\n",
    ")\n",
    "print()\n",
    "print(\"Ressources:\")\n",
    "print(f\" | CPU: {os.cpu_count()} cores\")\n",
    "\n",
    "PAPERS = \"Pandora Papers\"\n",
    "GRAPH_PATH = f\"./data/{PAPERS.lower().replace(' ', '_')}_graph.gexf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info pre filtering:\n",
      "Number of edges:  145874\n",
      "Number of nodes:  108053\n",
      "Number of weakly connected components:  2643\n",
      "\n",
      "Filtering the graph after the country \"Switzerland\"\n",
      "\n",
      "Info post filtering:\n",
      "Number of edges:  127482\n",
      "Number of nodes:  91864\n",
      "Number of weakly connected components:  53\n"
     ]
    }
   ],
   "source": [
    "# Graph mit allen Nodes/Edges von den gewählten Papers laden\n",
    "G = utils.get_graph(GRAPH_PATH, PAPERS)\n",
    "\n",
    "# Subgraph mit allen Nodes/Edges von Connected Components welche mindestens 1 Schweizer Adresse beinhalten\n",
    "G_swiss = utils.filter_graph_by_country_name(G, \"Switzerland\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specific analysis..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_officers_graph(G):\n",
    "    # Step 1: Make the original graph undirected\n",
    "    undirected_G = G.to_undirected()\n",
    "\n",
    "    # Step 2: Project the network to obtain a graph with only officers\n",
    "    officers_nodes = {node for node, data in undirected_G.nodes(data=True) if data.get(\"node_type\") == \"Officer\"}\n",
    "\n",
    "    connecting_entities = 0\n",
    "\n",
    "    # Step 3: Connect officers if they share the same address or entity\n",
    "    new_G = nx.Graph()\n",
    "    for node in officers_nodes:\n",
    "\n",
    "        # Check if the officer is related to an address or entity\n",
    "        related_nodes = set()\n",
    "        for neighbor in undirected_G.neighbors(node):\n",
    "            neighbor_data = undirected_G.nodes[neighbor]\n",
    "            if neighbor_data.get(\"node_type\") == \"Address\" or neighbor_data.get(\"node_type\") == \"Entity\":\n",
    "                related_nodes.add(neighbor)\n",
    "\n",
    "        # Add edges between officers if they share the same address or entity\n",
    "        for related_node in related_nodes:\n",
    "            for neighbor in undirected_G.neighbors(related_node):\n",
    "                if neighbor in officers_nodes:\n",
    "                    related_data = undirected_G.nodes[related_node]\n",
    "                    if related_data.get(\"node_type\") == \"Entity\":\n",
    "                        connecting_entities += 1\n",
    "                    new_G.add_edge(node, neighbor)\n",
    "\n",
    "    return new_G, connecting_entities\n",
    "\n",
    "# Create the new graph\n",
    "new_officers_graph, connecting_entities = project_officers_graph(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the new officers graph: 50452\n",
      "Ratio of swiss officers: 0.8550305240624753\n",
      "\n",
      "Number of edges in the new officers graph: 499061\n",
      "Number of edges in the new officers graph which stem from entities: 145212 (29.10%)\n",
      "Number of edges in the new officers graph which stem from addresses: 353849 (70.90%)\n",
      "\n",
      "Edge ratio (edges / max possible edges): 0.000392134869270035 which is equivalent to 0.0392134869270035 %\n"
     ]
    }
   ],
   "source": [
    "# List the number of edges and nodes\n",
    "num_nodes = len(new_officers_graph.nodes)\n",
    "num_edges = len(new_officers_graph.edges)\n",
    "\n",
    "print(\"Number of nodes in the new officers graph:\", num_nodes)\n",
    "\n",
    "all_officers_nodes = {node for node, data in G.nodes(data=True) if data.get(\"node_type\") == \"Officer\"}\n",
    "\n",
    "swiss_officers_nodes = {node for node, data in G_swiss.nodes(data=True) if data.get(\"node_type\") == \"Officer\"}\n",
    "\n",
    "swiss_officers_to_all_officers_raio = len(swiss_officers_nodes)/len(all_officers_nodes)\n",
    "\n",
    "print(f\"Ratio of swiss officers: {swiss_officers_to_all_officers_raio}\")\n",
    "print()\n",
    "\n",
    "print(\"Number of edges in the new officers graph:\", num_edges)\n",
    "print(f\"Number of edges in the new officers graph which stem from entities: {connecting_entities} ({connecting_entities/num_edges:.2%})\")\n",
    "print(f\"Number of edges in the new officers graph which stem from addresses: {num_edges-connecting_entities} ({(num_edges-connecting_entities)/num_edges:.2%})\")\n",
    "print()\n",
    "\n",
    "# Calculate the ratio of edges to the number of maximally possible edges\n",
    "max_possible_edges = num_nodes * (num_nodes - 1) / 2  # Complete graph formula\n",
    "edge_ratio = num_edges / max_possible_edges if max_possible_edges > 0 else 0  # To handle division by zero\n",
    "\n",
    "print(\"Edge ratio (edges / max possible edges):\", edge_ratio, \"which is equivalent to\", edge_ratio * 100, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new graph consists of 50k Officers (of which 86% are Swiss) and 500k Connections between them. Almost 30% of the newly created edges between the officers don't stem from addresses but fro entities they are connected to. This is important. Because officers having the same address will be a clique for sure and the ratio of swiss officers will be 100% or 0% depending on the address. But the fact that entities are also a connecting factor, makes the graph even interesting in the first place. As that's the only source where cliques can be multinational."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Find all cliques in the new officers graph\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m cliques \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mnx\u001b[49m\u001b[38;5;241m.\u001b[39mfind_cliques(new_officers_graph))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Print the number of cliques found\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of cliques found in the new officers graph:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(cliques))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nx' is not defined"
     ]
    }
   ],
   "source": [
    "# Find all cliques in the new officers graph\n",
    "cliques = list(nx.find_cliques(new_officers_graph))\n",
    "\n",
    "# Print the number of cliques found\n",
    "print(\"Number of cliques found in the new officers graph:\", len(cliques))\n",
    "\n",
    "# Get the length of each clique\n",
    "clique_lengths = [len(clique) for clique in cliques]\n",
    "\n",
    "# Count the frequency of each clique length\n",
    "clique_length_counts = Counter(clique_lengths)\n",
    "\n",
    "# Sort the clique lengths by frequency\n",
    "sorted_counts = sorted(clique_length_counts.items(), key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# Step 1: Get all Swiss officers\n",
    "swiss_officers = {node for node, data in G_swiss.nodes(data=True) if data.get(\"node_type\") == \"Officer\"}\n",
    "\n",
    "# Step 2 & 3: Calculate the ratio of Swiss officers for each clique size\n",
    "swiss_ratio_by_size = {}\n",
    "cliques_ratios = []\n",
    "\n",
    "for clique in cliques:\n",
    "    clique_size = len(clique)\n",
    "    \n",
    "    swiss_count = sum(1 for node in clique if node in swiss_officers)\n",
    "    swiss_ratio = swiss_count / clique_size if clique_size > 0 else 0\n",
    "    \n",
    "    # Skip cliques with size 1\n",
    "    if clique_size > 1:\n",
    "        cliques_ratios.append(swiss_ratio)\n",
    "    \n",
    "    if clique_size not in swiss_ratio_by_size:\n",
    "        swiss_ratio_by_size[clique_size] = {\"total_cliques\": 0, \"swiss_count\": 0}\n",
    "    \n",
    "    swiss_ratio_by_size[clique_size][\"total_cliques\"] += 1\n",
    "    swiss_ratio_by_size[clique_size][\"swiss_count\"] += swiss_count\n",
    "\n",
    "# Step 4: Calculate the ratio of Swiss officers for each clique size\n",
    "for size, data in swiss_ratio_by_size.items():\n",
    "    total_cliques = data[\"total_cliques\"]\n",
    "    swiss_count = data[\"swiss_count\"]\n",
    "    swiss_ratio = swiss_count / (total_cliques * size) if total_cliques > 0 else 0\n",
    "    swiss_ratio_by_size[size][\"swiss_ratio\"] = swiss_ratio\n",
    "    \n",
    "# Plot histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(cliques_ratios, edgecolor='black', alpha=0.7)\n",
    "ratio_dist = np.unique(cliques_ratios)\n",
    "plt.title(f'Distribution of Swiss Officer Ratio in Cliques (Excluding Size 1)\\n'\n",
    "          f'Number of unique ratios: {len(ratio_dist)} first five ratios: {ratio_dist[:5] if len(ratio_dist) > 5 else ratio_dist}')\n",
    "plt.xlabel('Swiss Officer Ratio')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Extract clique sizes and Swiss ratios\n",
    "clique_sizes = sorted(swiss_ratio_by_size.keys())\n",
    "swiss_ratios = [swiss_ratio_by_size[size]['swiss_ratio'] for size in clique_sizes]\n",
    "clique_counts = [swiss_ratio_by_size[size]['total_cliques'] for size in clique_sizes]\n",
    "\n",
    "# Plot the distribution as a bar plot with categorical x-axis\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar([str(size) for size in clique_sizes], swiss_ratios)\n",
    "plt.title('Distribution of Swiss Officer Ratio by Clique Size')\n",
    "plt.xlabel('Clique Size')\n",
    "plt.ylabel('Swiss Officer Ratio')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels by 45 degrees\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Add average line for Swiss officers ratio of 0.85\n",
    "plt.axhline(y=swiss_officers_to_all_officers_raio, color='red', linestyle='--', label=f'Average Swiss Officer Ratio ({swiss_officers_to_all_officers_raio:.3})')\n",
    "plt.legend()\n",
    "\n",
    "# Add clique counts as text labels inside the bars\n",
    "for bar, count in zip(bars, clique_counts):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, height, count, ha='center', va='top', rotation=90, color=\"white\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cliques are always swiss or not. And the rest of the cliques must most likely always be from a single country.\n",
    "\n",
    "So entities don't connect officers in a way to create multinational cliques."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "san-project-eQU7FBKZ-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
