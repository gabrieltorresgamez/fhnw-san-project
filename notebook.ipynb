{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 30%; float: right; margin: 10px; margin-right: 5%;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/FHNW_Logo.svg/2560px-FHNW_Logo.svg.png\" width=\"500\" style=\"float: left; filter: invert(50%);\"/>\n",
    "</div>\n",
    "\n",
    "<h1 style=\"text-align: left; margin-top: 10px; float: left; width: 60%;\">\n",
    "    SAN Projekt:<br> Schweizer Offshore Firmen\n",
    "</h1>\n",
    "\n",
    "<p style=\"clear: both; text-align: left;\">\n",
    "    Bearbeitet durch Florin Barbisch, Gabriel Torres Gamez und Tobias Buess im FS 2024.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir führen eine Voranalyse für das Bundesamt für Statistik durch, um die kürzlich aufgetretenen Leaks aus den Offshore Papers zu untersuchen. \n",
    "\n",
    "Diese Analyse zielt darauf ab, Umfang und Natur der Verbindungen in Schweizer Offshore-Strukturen zu ermitteln. Wir verwenden dafür Daten aus der [Offshore Leaks Database](https://offshoreleaks.icij.org/), um mögliche Muster, wichtige Personen aufzudecken, die für die Steuerbehörden oder Regulierungsorgane von Interesse sein könnten. \n",
    "\n",
    "Unsere Arbeit umfasst eine detaillierte Prüfung der betroffenen Entitäten. Dies wird es dem Bundesamt für Statistik ermöglichen, fundierte Entscheidungen zur weiteren Untersuchung und möglichen Massnahmen zu treffen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports und Einstellungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Environment:\n",
      " | Python version: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
      " | Numpy version: 1.26.4\n",
      " | Pandas version: 2.2.1\n",
      " | NetworkX version: 3.3\n",
      " | Matplotlib version: 3.8.4\n",
      " | CuGraph version: 24.04.00\n",
      "\n",
      "Ressources:\n",
      " | CPU: 24 cores\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# if cugraph is installed, import it\n",
    "cugraph_installed = False\n",
    "try:\n",
    "    import cugraph as cnx\n",
    "    cugraph_installed = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"Python Environment:\")\n",
    "print(f\" | Python version: {os.sys.version}\")\n",
    "print(f\" | Numpy version: {np.__version__}\")\n",
    "print(f\" | Pandas version: {pd.__version__}\")\n",
    "print(f\" | NetworkX version: {nx.__version__}\")\n",
    "print(f\" | Matplotlib version: {matplotlib.__version__}\")\n",
    "print(\n",
    "    f\" | CuGraph version: {cnx.__version__}\"\n",
    "    if cugraph_installed\n",
    "    else \" | CuGraph not installed\"\n",
    ")\n",
    "print()\n",
    "print(\"Ressources:\")\n",
    "print(f\" | CPU: {os.cpu_count()} cores\")\n",
    "\n",
    "PAPERS = \"Pandora Papers\"\n",
    "GRAPH_PATH = f\"./data/{PAPERS.lower().replace(' ', '_')}_graph.gexf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inhalt\n",
    "1. Wie sehen die Daten aus? Was für Informationen können wir daraus ziehen?\n",
    "2. Grobe Metriken zu Schweizer Officers und deren Offshore Firmen.\n",
    "3. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    # Stellen Sie sicher, dass der Text ein String ist\n",
    "    if isinstance(text, str):\n",
    "        # Entfernt alles außer Buchstaben, Ziffern, Leerzeichen und grundlegenden Satzzeichen\n",
    "        return re.sub(r\"[^\\w\\s,.]\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(GRAPH_PATH):\n",
    "    # read all the data\n",
    "    addressNodes = (\n",
    "        pd.read_csv(\"./data/nodes-addresses.csv\", low_memory=False, index_col=0)\n",
    "        .astype(str)\n",
    "        .map(remove_special_characters)\n",
    "    )\n",
    "    addressNodes[\"node_type\"] = \"Address\"\n",
    "\n",
    "    entityNodes = (\n",
    "        pd.read_csv(\"./data/nodes-entities.csv\", low_memory=False, index_col=0)\n",
    "        .astype(str)\n",
    "        .map(remove_special_characters)\n",
    "    )\n",
    "    entityNodes[\"node_type\"] = \"Entity\"\n",
    "\n",
    "    intermediaryNodes = (\n",
    "        pd.read_csv(\"./data/nodes-intermediaries.csv\", low_memory=False, index_col=0)\n",
    "        .astype(str)\n",
    "        .map(remove_special_characters)\n",
    "    )\n",
    "    intermediaryNodes[\"node_type\"] = \"Intermediary\"\n",
    "\n",
    "    officerNodes = (\n",
    "        pd.read_csv(\"./data/nodes-officers.csv\", low_memory=False, index_col=0)\n",
    "        .astype(str)\n",
    "        .map(remove_special_characters)\n",
    "    )\n",
    "    officerNodes[\"node_type\"] = \"Officer\"\n",
    "\n",
    "    nodes_others = (\n",
    "        pd.read_csv(\"./data/nodes-others.csv\", low_memory=False, index_col=0)\n",
    "        .astype(str)\n",
    "        .map(remove_special_characters)\n",
    "    )\n",
    "    nodes_others[\"node_type\"] = \"Other\"\n",
    "\n",
    "    relationships = (\n",
    "        pd.read_csv(\"./data/relationships.csv\", low_memory=False)\n",
    "        .set_index([\"node_id_start\", \"node_id_end\"])\n",
    "        .astype(str)\n",
    "        .map(remove_special_characters)\n",
    "    )\n",
    "\n",
    "    # filter all nodes and relationships that are not from the Pandora Papers\n",
    "    addressNodes = addressNodes[addressNodes[\"sourceID\"].str.contains(PAPERS)]\n",
    "    entityNodes = entityNodes[entityNodes[\"sourceID\"].str.contains(PAPERS)]\n",
    "    intermediaryNodes = intermediaryNodes[\n",
    "        intermediaryNodes[\"sourceID\"].str.contains(PAPERS)\n",
    "    ]\n",
    "    officerNodes = officerNodes[officerNodes[\"sourceID\"].str.contains(PAPERS)]\n",
    "    nodes_others = nodes_others[nodes_others[\"sourceID\"].str.contains(PAPERS)]\n",
    "\n",
    "    # alternatively, get all nodeIDs from all filtered nodes and remove relationships with nodeIDs that are not in this list\n",
    "    allNodeIDs = pd.concat(\n",
    "        [addressNodes, entityNodes, intermediaryNodes, officerNodes, nodes_others]\n",
    "    ).index\n",
    "    relationships = relationships[\n",
    "        relationships.index.get_level_values(0).isin(allNodeIDs)\n",
    "        & relationships.index.get_level_values(1).isin(allNodeIDs)\n",
    "    ]\n",
    "\n",
    "    # create the graph\n",
    "    G = nx.MultiDiGraph()\n",
    "    G.add_nodes_from(\n",
    "        [(key, value) for key, value in addressNodes.to_dict(\"index\").items()]\n",
    "    )\n",
    "    G.add_nodes_from(\n",
    "        [(key, value) for key, value in entityNodes.to_dict(\"index\").items()]\n",
    "    )\n",
    "    G.add_nodes_from(\n",
    "        [(key, value) for key, value in intermediaryNodes.to_dict(\"index\").items()]\n",
    "    )\n",
    "    G.add_nodes_from(\n",
    "        [(key, value) for key, value in officerNodes.to_dict(\"index\").items()]\n",
    "    )\n",
    "    G.add_nodes_from(\n",
    "        [(key, value) for key, value in nodes_others.to_dict(\"index\").items()]\n",
    "    )\n",
    "    G.add_edges_from(\n",
    "        [\n",
    "            (*relationships.index[i], value)\n",
    "            for i, value in enumerate(relationships.to_dict(orient=\"records\"))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # remove all the dataframes\n",
    "    del addressNodes\n",
    "    del entityNodes\n",
    "    del intermediaryNodes\n",
    "    del officerNodes\n",
    "    del nodes_others\n",
    "    del relationships\n",
    "\n",
    "    # save the graph\n",
    "    nx.write_gexf(G, GRAPH_PATH)\n",
    "\n",
    "    # remove the graph\n",
    "    del G\n",
    "\n",
    "G = nx.read_gexf(GRAPH_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wie sehen die Daten aus? Was für Informationen können wir daraus ziehen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grobe Metriken zu schweizer Officers und deren Offshore Firmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "san-project-eQU7FBKZ-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
