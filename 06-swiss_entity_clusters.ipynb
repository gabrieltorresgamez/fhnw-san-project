{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 30%; float: right; margin: 10px; margin-right: 5%;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/FHNW_Logo.svg/2560px-FHNW_Logo.svg.png\" width=\"500\" style=\"float: left; filter: invert(50%);\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "<h1 style=\"text-align: left; margin-top: 10px; float: left; width: 60%;\">\n",
    "    SAN Projekt:<br> Schweizer Offshore Firmen\n",
    "</h1>\n",
    "\n",
    "\n",
    "<p style=\"clear: both; text-align: left;\">\n",
    "    Bearbeitet durch Florin Barbisch, Gabriel Torres Gamez und Tobias Buess im FS 2024.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir führen eine Voranalyse für das Bundesamt für Statistik durch, um die kürzlich aufgetretenen Leaks aus den Offshore Papers zu untersuchen. \n",
    "\n",
    "\n",
    "Diese Analyse zielt darauf ab, Umfang und Natur der Verbindungen in Schweizer Offshore-Strukturen zu ermitteln. Wir verwenden dafür Daten aus der [Offshore Leaks Database](https://offshoreleaks.icij.org/), um mögliche Muster, wichtige Personen aufzudecken, die für die Steuerbehörden oder Regulierungsorgane von Interesse sein könnten. \n",
    "\n",
    "\n",
    "Unsere Arbeit umfasst eine detaillierte Prüfung der betroffenen Entitäten. Dies wird es dem Bundesamt für Statistik ermöglichen, fundierte Entscheidungen zur weiteren Untersuchung und möglichen Massnahmen zu treffen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports und Einstellungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Environment:\n",
      " | Python version: 3.12.2 (tags/v3.12.2:6abddd9, Feb  6 2024, 21:26:36) [MSC v.1937 64 bit (AMD64)]\n",
      " | Numpy version: 1.26.4\n",
      " | Pandas version: 2.2.2\n",
      " | Matplotlib version: 3.9.0\n",
      " | NetworkX version: 3.3\n",
      " | NetworkX backend: None\n",
      " | CuGraph not installed, for better performance install it like this:\n",
      "\tpip install cugraph-cu12 --extra-index-url=https://pypi.ngc.nvidia.com\n",
      "\n",
      "Ressources:\n",
      " | CPU: 12 cores\n"
     ]
    }
   ],
   "source": [
    "# Python internal modules\n",
    "import os\n",
    "\n",
    "# Project modules\n",
    "import utils\n",
    "\n",
    "# External modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BACKEND = None  # use default\n",
    "if \"cugraph\" in nx.utils.backends.backends.keys():\n",
    "    import nx_cugraph as nxcg\n",
    "    BACKEND = \"cugraph\"\n",
    "\n",
    "print(\"Python Environment:\")\n",
    "print(f\" | Python version: {os.sys.version}\")\n",
    "print(f\" | Numpy version: {np.__version__}\")\n",
    "print(f\" | Pandas version: {pd.__version__}\")\n",
    "print(f\" | Matplotlib version: {matplotlib.__version__}\")\n",
    "print(f\" | NetworkX version: {nx.__version__}\")\n",
    "print(f\" | NetworkX backend: {BACKEND}\")\n",
    "print(\n",
    "    f\" | CuGraph version: {nxcg.__version__}\"\n",
    "    if BACKEND == \"cugraph\"\n",
    "    else \" | CuGraph not installed, for better performance install it like this:\\n\\tpip install cugraph-cu12 --extra-index-url=https://pypi.ngc.nvidia.com\"\n",
    ")\n",
    "print()\n",
    "print(\"Ressources:\")\n",
    "print(f\" | CPU: {os.cpu_count()} cores\")\n",
    "\n",
    "PAPERS = \"Pandora Papers\"\n",
    "GRAPH_PATH = f\"./data/{PAPERS.lower().replace(' ', '_')}_graph.gexf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 108053\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f4e6a7769f5453094c8fd2ba99c297f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Merging duplicate nodes:   0%|          | 0/89015 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes after removing duplicates: 89015\n",
      "Number of edges: 126762\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672002dc3b0a494a9dca8103bd0abdb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Removing duplicate edges:   0%|          | 0/126762 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges after removing duplicates: 111962\n"
     ]
    }
   ],
   "source": [
    "G = utils.get_graph(GRAPH_PATH, PAPERS)\n",
    "\n",
    "print(f\"Number of nodes: {len(G.nodes)}\")\n",
    "G = utils.merge_duplicate_nodes(\n",
    "    G, exclude_attributes=[\"label\", \"countries\", \"sourceID\", \"valid_until\", \"note\"]\n",
    ")\n",
    "print(f\"Number of nodes after removing duplicates: {len(G.nodes)}\")\n",
    "\n",
    "print(f\"Number of edges: {len(G.edges)}\")\n",
    "G = utils.remove_duplicate_edges(G)\n",
    "print(f\"Number of edges after removing duplicates: {len(G.edges)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Entity Clusters with high swiss connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original graph: 89015 nodes, 111962 edges\n",
      "officers_entities_subgraph: 60872 nodes, 54437 edges\n"
     ]
    }
   ],
   "source": [
    "officers = utils.filter_nodes(G, query=\"node_type == 'Officer'\")\n",
    "entities = utils.filter_nodes(G, query=\"node_type == 'Entity'\")\n",
    "officers_entities_subgraph = G.subgraph(set(officers) | set(entities))\n",
    "\n",
    "print(f\"original graph: {len(G.nodes)} nodes, {len(G.edges)} edges\")\n",
    "print(\n",
    "    f\"officers_entities_subgraph: {len(officers_entities_subgraph.nodes)} nodes, {len(officers_entities_subgraph.edges)} edges\"\n",
    ")\n",
    "\n",
    "nx.projected_graph(officers_entities_subgraph, entities).name = \"Entities\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "san-project-eQU7FBKZ-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
